{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "33d86f60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [04:14<00:00,  5.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 data 가져오기 성공\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#불러올 페이지 수 (총 7222페이지)\n",
    "i = 50\n",
    "count = 0\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(1,(i+1))):\n",
    "    requestURL = 'https://nedrug.mfds.go.kr/searchDrug?sort=&sortOrder=&searchYn=&ExcelRowdata=&page='+str(i)+'&searchDivision=detail&itemName=&entpName=&ingrName1=&ingrName2=&ingrName3=&itemSeq=&stdrCodeName=&atcCodeName=&indutyClassCode=&sClassNo=&narcoticKindCode=&cancelCode=&etcOtcCode=&makeMaterialGb=&searchConEe=AND&eeDocData=&searchConUd=AND&udDocData=&searchConNb=AND&nbDocData=&startPermitDate=&endPermitDate='\n",
    "    res = requests.get(requestURL)\n",
    "    html_doc = res.text\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    #print(soup.prettify())\n",
    "    \n",
    "    #각 제품의 request보낼 url모으기\n",
    "    itemSeqList=[]\n",
    "    links = soup.find_all(\"a\")\n",
    "    for a in links:\n",
    "        href = a.attrs['href']\n",
    "        if \"itemSeq\" in href:\n",
    "            #print(href)\n",
    "            itemSeqList.append(href)\n",
    "        if len(itemSeqList) == 15:\n",
    "            break\n",
    "    #print(itemSeqList)\n",
    "    \n",
    "    #한 페이지당 15개 data가 있음\n",
    "    #data 가져오기\n",
    "    for j in range(0,len(itemSeqList)):\n",
    "        cindex = []\n",
    "        rindex = [str(j+1)]\n",
    "        \n",
    "        detailURL='https://nedrug.mfds.go.kr'+str(itemSeqList[j])\n",
    "        res2 = requests.get(detailURL)\n",
    "        html_doc2 = res2.text\n",
    "        soup2 =BeautifulSoup(html_doc2, 'html.parser')\n",
    "        #print(soup2.prettify())\n",
    "            \n",
    "        #col index 가져오기\n",
    "        FILTER = ['년도','생산실적','순번','변경일자','변경항목'] #여기에 해당되는건 NO\n",
    "        for title in soup2.find_all('th'):\n",
    "            if(title.get_text() in FILTER):\n",
    "                break;\n",
    "            cindex.append(title.get_text())\n",
    "        datalist = []\n",
    "        flag = 0\n",
    "        for DATA in soup2.find_all('td'):\n",
    "            #print(DATA.get_text())\n",
    "            flag += 1\n",
    "            datalist.append(DATA.get_text())\n",
    "            if(flag == len(cindex)):\n",
    "                break\n",
    "                \n",
    "        #유효성분 가져오기\n",
    "        cindex.append(\"유효성분\")\n",
    "        ingredient = soup2.find_all('h3', class_='cont_title3 mt27 pb10')\n",
    "        if ingredient:\n",
    "            for ing in ingredient:\n",
    "                datalist.append(ing.get_text().replace('유효성분 : ',''))\n",
    "        else :\n",
    "            datalist.append(\"\")\n",
    "            \n",
    "        #유효성분 분량 가져오기\n",
    "        #나중에 여기서 a[0]으로 세세히 나눌 수 있을 듯?\n",
    "        cindex.append(\"분량\")\n",
    "        amount = soup2.find_all('p', class_='note')\n",
    "        adic = {}\n",
    "        for alist in amount:\n",
    "            temp = alist.get_text()\n",
    "            a = temp.split('\\xa0\\xa0|\\xa0\\xa0')            \n",
    "            #print(temp)\n",
    "            if a[0] != '조회 결과가 없습니다.':\n",
    "                i_name = a[1].replace('성분명 : ','')\n",
    "                i_amount = a[2].replace('분량 : ',' ')\n",
    "                i_unit = a[3].replace('단위 : ', '')\n",
    "                #print(i_name + i_amount + i_unit)\n",
    "                adic[i_name] = i_amount+i_unit\n",
    "        if adic == {}:\n",
    "            datalist.append(\"\")\n",
    "        else:\n",
    "            s = \"\"\n",
    "            itemList = adic.items()\n",
    "            for item in itemList:\n",
    "                s += item[0] + \" :\" + item[1] + \"\\n\"\n",
    "            datalist.append(s)\n",
    "            \n",
    "        #효능효과 추가하기\n",
    "        cindex.append(\"효능효과\")\n",
    "        way = soup2.find_all('div', id ='_ee_doc')\n",
    "        s = \"\"\n",
    "        for w in way:\n",
    "            s += w.get_text()\n",
    "        \n",
    "        datalist.append(s)\n",
    "        \n",
    "        #용법용량 추가하기\n",
    "        cindex.append(\"용법용량\")\n",
    "        way = soup2.find_all('div', id ='_ud_doc')\n",
    "        s = \"\"\n",
    "        for w in way:\n",
    "            s += w.get_text()\n",
    "        \n",
    "        datalist.append(s)\n",
    "        \n",
    "        #주의사항 추가하기\n",
    "        cindex.append(\"주의사항\")\n",
    "        way = soup2.find_all('div', id ='_nb_doc')\n",
    "        s = \"\"\n",
    "        for w in way:\n",
    "            s += w.get_text()\n",
    "        \n",
    "        datalist.append(s)\n",
    "        \n",
    "            \n",
    "        #URL 추가하기\n",
    "        cindex.append(\"URL\")\n",
    "        datalist.append(detailURL)\n",
    "        \n",
    "        #추출 후 남은 데이터\n",
    "        cindex.append(\"추출 후 남은 데이터\")\n",
    "        datalist.append(\"#none\")\n",
    "        \n",
    "        #데이터 값 수정\n",
    "        datalist[6] = \"kdrug-\" + datalist[6]\n",
    "        for i in range(len(cindex)):\n",
    "            datalist[i] = datalist[i].replace('제조일로부터 ','')\n",
    "        #데이터 프레임 만들기\n",
    "        temp = pd.DataFrame(data= [datalist],index=rindex, columns = cindex)\n",
    "        \n",
    "        \n",
    "        #데이터 프레임 합치기\n",
    "        df = pd.concat([df, temp])\n",
    "        \n",
    "        \n",
    "\n",
    "df.to_excel(\"크롤링한 모든 데이터(의약품안전나라).xlsx\", index = False )\n",
    "print(\"전체 data 가져오기 성공\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a083e79e",
   "metadata": {},
   "source": [
    "<h2>필요한 열만 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "89282b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 excel파일 생성 완료\n"
     ]
    }
   ],
   "source": [
    "finalDf = df[['품목기준코드','제품명','업체명','성상','유효성분','분량','효능효과','용법용량','주의사항','전문/일반','저장방법','사용기간','포장정보','URL','추출 후 남은 데이터']]\n",
    "finalDf.rename(columns={'품목기준코드':'제품코드','업체명':'제조사'},inplace=True)\n",
    "finalDf.to_excel(\"result(의약품안전나라).xlsx\", index = False)\n",
    "print(\"최종 excel파일 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347293e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
